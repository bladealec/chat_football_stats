{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec44b9b",
   "metadata": {},
   "source": [
    "# This notebook gathers data of NISA team stadings tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a51f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc63f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional cell, stretches cell width for better readability\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "custom_css = \"\"\"\n",
    "<style>\n",
    ".container { width: 100% !important; }\n",
    ".code_cell { flex-grow: 1; width: 100% !important; }\n",
    ".code_cell .input_area { width: 100% !important; }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(custom_css))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3650f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_standings_table(soup):\n",
    "    \n",
    "    table = soup.find('table')\n",
    "    \n",
    "     # Extract the table data into a list of dictionaries\n",
    "    data = []\n",
    "    rows = table.find_all('tr')\n",
    "    headers = [header.get_text(strip=True) for header in rows[0].find_all('th')]\n",
    "    \n",
    "    for row in rows[1:]:\n",
    "        values = [cell.get_text(strip=True) for cell in row.find_all(['td', 'th'])]\n",
    "        data.append(dict(zip(headers, values)))\n",
    "\n",
    "    # Creating DataFrame\n",
    "    team_standings_df = pd.DataFrame(data)\n",
    "\n",
    "    # Cleaning up DataFrame\n",
    "    team_standings_df = team_standings_df.replace(r'\\n', '', regex=True)  # Removes newline characters\n",
    "    team_standings_df['TEAM'] = team_standings_df['TEAM'].str.strip()  # Strips leading/trailing spaces\n",
    "\n",
    "    return(team_standings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35aa19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(csv_filename):\n",
    "    \n",
    "    soup = BS(driver.page_source,'html.parser')\n",
    "    \n",
    "    team_standings_df = extract_standings_table(soup)\n",
    "    \n",
    "    # Creates a \"data\" folder if it doesn't exist\n",
    "    data_folder = 'data'\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "    \n",
    "    #Saves the dataframe locally to a csv\n",
    "    csv_filepath = os.path.join(data_folder, csv_filename)\n",
    "    team_standings_df.to_csv(csv_filepath, index=False)\n",
    "    \n",
    "    print(team_standings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_table(desired_table, year, file_name):\n",
    "    \n",
    "    # Finding all available options in the dropdown list for tables and initialize the selected option ID\n",
    "    options = driver.find_elements(By.CSS_SELECTOR, 'li.select2-results__option')\n",
    "    dynamic_part = None\n",
    "\n",
    "    # Looping through the available options to find the desired year group\n",
    "    for option in options:\n",
    "        # Getting the year group options, which are elements with class \"select2-results__group\"\n",
    "        year_group = option.find_elements(By.CLASS_NAME, 'select2-results__group')\n",
    "        # Checking if the desired year is in the text of any year group option\n",
    "        if year in [group.get_attribute('innerText') for group in year_group]:\n",
    "            # If the desired year is found in a year group option then we check the nested options for the desired table\n",
    "            nested_options = option.find_elements(By.CLASS_NAME, 'select2-results__option')\n",
    "            for nested_option in nested_options:\n",
    "                # Checking if the desired table is in the text of the nested option\n",
    "                if desired_table in nested_option.get_attribute('innerText'):\n",
    "                    # If the desired table is found then we get its ID, which is used to select the option\n",
    "                    dynamic_part = nested_option.get_attribute('id')\n",
    "                    break\n",
    "            if dynamic_part:\n",
    "                break\n",
    "\n",
    "    if not dynamic_part:\n",
    "        print(f\"No option found for {desired_table} in {year}\")\n",
    "    else:\n",
    "        table_select = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.CSS_SELECTOR, f'#{dynamic_part}')))\n",
    "        table_select.click()\n",
    "\n",
    "        create_df(file_name)\n",
    "\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052bfdbe",
   "metadata": {},
   "source": [
    "### Run the below cell to see all the tables you can download.\n",
    "#### (Independent cups for 2023 and 2022 are currenlty unavailable on the NISA website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a4bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting Chrome with Selenium\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigating to the page\n",
    "URL = 'https://nisaofficial.com/standings'\n",
    "driver.get(URL)\n",
    "\n",
    "# Interacting with the page to get to the dropdown selector\n",
    "button1 = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '#selectSeason')))\n",
    "button1.click()\n",
    "\n",
    "button2 = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '#select2-year-container')))\n",
    "button2.click()\n",
    "\n",
    "# Extracting the HTML code of the dropdown options\n",
    "dropdown_html_code = driver.find_element(By.CLASS_NAME, 'select2-results').get_attribute('outerHTML')\n",
    "\n",
    "# Finding all the options in the dropdown selector\n",
    "dropdown_soup = BS(dropdown_html_code, 'html.parser')\n",
    "options = dropdown_soup.select('li.select2-results__option')\n",
    "\n",
    "for option in options:\n",
    "    print(option.text)\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb2e5c",
   "metadata": {},
   "source": [
    "### Table Selection\n",
    "#### Run both cells for every table you want to download. All you need to do is change are the arguements in the 'download_table()' function. The first arguement is the table you want to download, the second arguement is what year you want to pull a table from, and the third is what you want the file to be called. You will need to end the file name with '.csv' and the file will be downloaded into a directory called 'data'. You do not have to create this directory yourself. The 'create_df()' function will do this for you. Finally, make sure your agruements are encased in apostrophes or quotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8dadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting Chrome with Selenium\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigating to the page\n",
    "URL = 'https://nisaofficial.com/standings'\n",
    "driver.get(URL)\n",
    "\n",
    "# Interacting with the page to get to the dropdown selector\n",
    "button1 = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '#selectSeason')))\n",
    "button1.click()\n",
    "\n",
    "button2 = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '#select2-year-container')))\n",
    "button2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ff5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_table('2023 Season', '2023', '2023_standings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f32903",
   "metadata": {},
   "source": [
    "## Use the below cell to download all Regular Season Standings Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b20f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "season = ['Spring Season', 'Fall Season', 'Spring Season', 'Fall Season', '2022 Season', '2023 Season']\n",
    "year = ['2019-2020', '2020-2021', '2020-2021', '2021', '2022', '2023']\n",
    "file_name = ['2020_spring_standings.csv', '2020_fall_standing.csv', '2021_spring_standings.csv', '2021_fall_standings.csv', '2022_standings.csv', '2023_standings.csv']\n",
    "\n",
    "# Loop through the years and download tables\n",
    "for i in range(len(year)):\n",
    "    print(f'\\nLeague Standings for {year[i]}')\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    URL = 'https://nisaofficial.com/standings'\n",
    "    driver.get(URL)\n",
    "    \n",
    "    # Interacting with the page to get to the dropdown selector\n",
    "    button1 = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '#selectSeason')))\n",
    "    button1.click()\n",
    "\n",
    "    button2 = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '#select2-year-container')))\n",
    "    button2.click()\n",
    "\n",
    "    download_table(season[i], year[i], file_name[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4761de98",
   "metadata": {},
   "source": [
    "## Below will concat all the tables into one, given you used the same file naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ef2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "\n",
    "# Read and preprocess data for each year\n",
    "for i in range(len(year)):\n",
    "    file = file_name[i]\n",
    "    df = pd.read_csv(f'data/{file}', index_col=0)\n",
    "    \n",
    "    df = df.iloc[:, 1:]\n",
    "    \n",
    "    df['Year'] = year[i]\n",
    "    df['Season'] = season[i]\n",
    "    \n",
    "    data_frames.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "complete_regseason_standings_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Extracts year based on the 'Season' column\n",
    "def get_year(row):\n",
    "    if row['Season'] == 'Spring Season':\n",
    "        return row['Year'].split('-')[1]\n",
    "    elif row['Season'] == 'Fall Season':\n",
    "        return row['Year'].split('-')[0]\n",
    "    else:\n",
    "        return row['Year']\n",
    "\n",
    "# Replacing 'Year' column\n",
    "complete_regseason_standings_df['Year'] = complete_regseason_standings_df.apply(get_year, axis=1)\n",
    "\n",
    "# Add a new 'Year and Season' column\n",
    "complete_regseason_standings_df['Year and Season'] = complete_regseason_standings_df['Year'] + ' ' + complete_regseason_standings_df['Season']\n",
    "\n",
    "# Change column names\n",
    "column_name_mapping = {\n",
    "    'GP': 'Games Played',\n",
    "    'W': 'Wins',\n",
    "    'D': 'Draws',\n",
    "    'L': 'Losses',\n",
    "    'H (W-D-L)': 'Home Record (W-D-L)',\n",
    "    'A (W-D-L)': 'Away Record (W-D-L)',\n",
    "    'Latest': 'Latest Record',\n",
    "    'GF': 'Goals For',\n",
    "    'GA': 'Goals Against',\n",
    "    'GD': 'Goal Difference',\n",
    "    'PTS': 'Points',\n",
    "}\n",
    "\n",
    "complete_regseason_standings_df = complete_regseason_standings_df.rename(columns=column_name_mapping)\n",
    "\n",
    "# Save the concatenated DataFrame to a CSV file\n",
    "complete_regseason_standings_df.to_csv('complete_regseason_standings.csv', index=False)\n",
    "\n",
    "print(complete_regseason_standings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d590bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
